{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dafc571",
   "metadata": {},
   "source": [
    "# **Sprint 8**\n",
    "## 5. Análisis de duración de viajes — sábados (Loop --> O'Hare)\n",
    "\n",
    "Este cuaderno implementa un flujo **limpio, modular y reproducible** para analizar la duración de los viajes en taxi desde el Loop hacia el Aeropuerto O'Hare, restringido a los **sábados**.  \n",
    "\n",
    "El objetivo es doble:  \n",
    "1. **Diagnóstico exploratorio**: caracterizar la distribución de la duración y su relación con la condición climática (lluvioso vs. sin lluvia).  \n",
    "2. **Inferencia robusta**: aplicar pruebas estadísticas y tamaños de efecto que permitan decidir si la diferencia observada es significativa y relevante en la práctica.\n",
    "\n",
    "---\n",
    "\n",
    "### **Estructura del notebook**\n",
    "1. **Configuración de parámetros**: define semillas, umbrales y estética de gráficos para asegurar reproducibilidad.  \n",
    "2. **Carga de datos**: ingesta segura y validación inicial de columnas clave.  \n",
    "3. **Utilidades**: funciones auxiliares para formateo, normalidad, tamaños de efecto e intervalos de confianza bootstrap.  \n",
    "4. **Limpieza y validación**: reglas realistas (plausibilidad, IQR, nulos), garantizando un dataset confiable.  \n",
    "5. **Análisis Exploratorio de Datos (AED)**: métricas descriptivas, tendencias temporales y distribuciones por clima.  \n",
    "6. **Supuestos y pruebas**: árbol de decisión para seleccionar la prueba adecuada (t/Welch o Mann–Whitney) y cálculo de tamaños de efecto.  \n",
    "7. **Comparación visual final**: violín + box + jitter resaltando media/mediana para comunicar diferencias de manera intuitiva.  \n",
    "8. **Conclusiones**: salida compacta en Markdown con interpretación estadística, magnitud práctica e implicaciones accionables.\n",
    "\n",
    "---\n",
    "\n",
    "### **Valor esperado**\n",
    "Este sprint no solo busca determinar si existe una diferencia estadísticamente significativa en la duración de los viajes según el clima, sino también **cuantificar su magnitud práctica**, **evaluar su robustez** y **generar insumos claros para la toma de decisiones operativas y de comunicación**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dcd0b9",
   "metadata": {},
   "source": [
    "## 1. Parámetros globales y carga de datos\n",
    "\n",
    "### **Objetivo**  \n",
    "Definir parámetros que gobiernan el análisis y la reproducibilidad, cargar el CSV con la columna temporal correctamente parseada y preparar la estética de los gráficos junto con formateadores numéricos en estilo es-MX.\n",
    "\n",
    "### **Qué hace este bloque y por qué**  \n",
    "- **Opciones de visualización**: configura `pandas` para mostrar todas las columnas y ampliar el ancho de salida, facilitando la inspección de los datos en Jupyter.  \n",
    "- **Parámetros del flujo**: se fijan valores globales como:  \n",
    "  - `ALFA`: nivel de significancia para pruebas estadísticas.  \n",
    "  - `GRAF` y `EDA`: switches para controlar si se grafican métricas y se imprimen resultados descriptivos.  \n",
    "  - `NBOOT`: número de réplicas bootstrap para análisis no paramétricos.  \n",
    "  - `RM_OUT`: decisión sobre remover atípicos mediante IQR.  \n",
    "  - `MIN_S` y `MAX_S`: umbrales realistas de duración (20 a 90 min).  \n",
    "  - `RNG_SEED`: semilla para reproducibilidad en cálculos aleatorios.  \n",
    "- **Carga robusta**: lectura del archivo `project_sql_result_07.csv` con `try/except`, parseando `start_ts` a `datetime` para habilitar operaciones temporales. Se imprime la cantidad de filas y las primeras observaciones. Si falla, se inicializa `df` vacío y se muestra el error.  \n",
    "- **Estética unificada**: `matplotlib.rcParams` se actualiza para asegurar consistencia visual en todas las gráficas (tamaño, grilla tenue, tipografías).  \n",
    "- **Formateadores numéricos es-MX**:  \n",
    "  - `fmt_miles_es`: para formatear ticks en ejes (`FuncFormatter`).  \n",
    "  - `str_miles_es`: para etiquetas de valores en barras.  \n",
    "  Ambos utilizan separador de miles con punto y coma decimal, siguiendo la convención local.\n",
    "\n",
    "### **Supuestos y alcance de este paso**  \n",
    "- Solo se parsea `start_ts`, aún no se renombran columnas ni se aplican filtros de límites o outliers.  \n",
    "- El pipeline posterior debe validar que `df` no esté vacío si la carga falla.\n",
    "\n",
    "### **Resultados esperados**  \n",
    "- `df` cargado con `start_ts` en formato `datetime64[ns]`.  \n",
    "- Vista preliminar de las primeras filas.  \n",
    "- Estética de gráficos y formateadores numéricos listos para usarse en los análisis posteriores.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parámetros globales y semillas — controlan todo el flujo ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Mostrar dataframes cómodamente en Jupyter (todas las columnas, ancho mayor)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Hiperparámetros del análisis\n",
    "ALFA    = 0.05   # Nivel de significancia para pruebas estadísticas\n",
    "GRAF    = True   # Mostrar (True) u ocultar (False) gráficas\n",
    "EDA     = True   # Imprimir (True) u omitir (False) métricas descriptivas\n",
    "NBOOT   = 9999   # Réplicas bootstrap (si se usan más adelante)\n",
    "RM_OUT  = True   # Remover atípicos por IQR (si se aplica después en el flujo)\n",
    "MIN_S   = 1200   # Límite inferior realista de duración en segundos (20 min)\n",
    "MAX_S   = 5400   # Límite superior realista de duración en segundos (1.5 h)\n",
    "RNG_SEED = 12345 # Semilla para reproducibilidad\n",
    "\n",
    "# (Opcional) Fijar semilla para cualquier rutina aleatoria posterior\n",
    "# np.random.seed(RNG_SEED)\n",
    "\n",
    "# --- Carga de datos ---\n",
    "try:\n",
    "    # Lee el CSV y parsea 'start_ts' como datetime para habilitar operaciones .dt\n",
    "    df = pd.read_csv('../data/project_sql_result_07.csv', parse_dates=['start_ts'])\n",
    "    print(\"Datos cargados con éxito. Filas:\", len(df))\n",
    "    display(df.head(5))\n",
    "except Exception as e:\n",
    "    # Si falla la carga, dejamos df vacío (el resto del pipeline debe validar esto)\n",
    "    print(\"Error cargando datos:\", e)\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "\n",
    "# --- Estética consistente de gráficos ---\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (11, 5.5),   # tamaño por defecto de figuras\n",
    "    \"figure.dpi\": 120,             # resolución\n",
    "    \"axes.grid\": True,             # activar grilla suave\n",
    "    \"grid.alpha\": 0.6,\n",
    "    \"grid.linewidth\": 0.5,\n",
    "    \"axes.spines.top\": False,      # quitar bordes superior/derecho\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.titlesize\": 12,\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "})\n",
    "\n",
    "def fmt_miles_es(x, pos=None):\n",
    "    \"\"\"\n",
    "    Devuelve un string para formatear valores numéricos en ejes (es-MX).\n",
    "    \n",
    "    Reglas:\n",
    "    - |x| < 1000 → un decimal.\n",
    "    - Si no, entero con separador de miles.\n",
    "    - Intercambia coma/punto para estándar español (1.234,5).\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    x : float\n",
    "        Valor numérico a formatear (lo provee Matplotlib).\n",
    "    pos : int, opcional\n",
    "        Índice del tick (no se usa; está para compatibilidad con FuncFormatter).\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    str\n",
    "        Número formateado con convención es-MX.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    s = f\"{x:,.1f}\" if abs(x) < 1000 else f\"{int(round(x)):,}\"\n",
    "    return s.replace(\",\", \"_\").replace(\".\", \",\").replace(\"_\", \".\")\n",
    "\n",
    "def str_miles_es(x, dec=1):\n",
    "    \"\"\"\n",
    "    Devuelve un string formateado (es-MX) para anotar valores dentro de las gráficas.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    x : float or int\n",
    "        Valor a formatear.\n",
    "    dec : int, por defecto 1\n",
    "        Decimales cuando |x| < 1000.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    str\n",
    "        Representación en string con separador de miles y coma decimal.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    if isinstance(x, float) and abs(x) < 1000:\n",
    "        s = f\"{x:.{dec}f}\"\n",
    "    else:\n",
    "        s = f\"{int(round(x)):,}\"\n",
    "    return s.replace(\",\", \"_\").replace(\".\", \",\").replace(\"_\", \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82065a",
   "metadata": {},
   "source": [
    "## 2. Renombrado, normalización y filtrado inicial\n",
    "\n",
    "### **Objetivo**  \n",
    "Estandarizar el esquema de columnas y la codificación de clima; asegurar tipos correctos; aplicar un filtro de plausibilidad de duración y (opcionalmente) remover atípicos por IQR, preparando un dataset consistente para el EDA y las pruebas.\n",
    "\n",
    "### **Qué hace este bloque y por qué**  \n",
    "- **Estandarización de columnas** (`ren`): unifica nombres (`inicio_ts`, `clima`, `duracion_s`) y hace cast robusto a `datetime`/numérico.  \n",
    "- **Normalización de clima**: mapea variantes comunes (`bad/good`, `rainy/clear`) a dos niveles canónicos: `lluvioso` y `sin lluvia`.  \n",
    "- **Plausibilidad de duración**: aplica límites realistas (`MIN_S=1200`, `MAX_S=5400`) para descartar registros imposibles o no representativos.  \n",
    "- **Atípicos por grupo (opcional)**: si `RM_OUT=True`, elimina outliers por la regla IQR **dentro de cada categoría de clima**, evitando sesgar comparaciones.\n",
    "\n",
    "### **Supuestos y alcance**  \n",
    "- Los datos contienen, al menos, `inicio_ts`, `clima` y `duracion_s` tras el renombrado.  \n",
    "- La normalización de `clima` cubre las variantes esperadas; valores desconocidos se asignan a `sin lluvia`.  \n",
    "- La limpieza por IQR es **diagnóstica** y debe reportarse cuando se emplea (impacto en N y distribución).\n",
    "\n",
    "### **Resultados esperados**  \n",
    "- `df_filtrado` con esquema y tipos consistentes, sin duraciones fuera de rango, y con outliers removidos (si corresponde).  \n",
    "- Un conteo claro de filas resultantes para trazar el linaje de datos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Renombrado y normalización (bad/good -> lluvioso/sin lluvia) ---\n",
    "def ren(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estandariza nombres de columnas y normaliza la variable categórica de clima.\n",
    "\n",
    "    - Renombra columnas posibles del CSV a un esquema consistente:\n",
    "      * start_ts / inicio_ts -> 'inicio_ts' (datetime)\n",
    "      * weather_conditions / condiciones_climaticas -> 'clima' (str normalizada)\n",
    "      * duration_seconds / duracion_segundos -> 'duracion_s' (num)\n",
    "    - Convierte tipos: 'inicio_ts' a datetime y 'duracion_s' a numérico.\n",
    "    - Normaliza 'clima' a {'lluvioso', 'sin lluvia'} mapeando variantes comunes.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Datos crudos tras la lectura del CSV.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Copia del DataFrame con columnas estandarizadas y 'clima' normalizado.\n",
    "\n",
    "    Lanza\n",
    "    -----\n",
    "    ValueError\n",
    "        Si faltan columnas requeridas tras el renombrado.\n",
    "    \"\"\"\n",
    "    # Mapeo flexible de nombres de columnas -> estándar interno\n",
    "    m = {\n",
    "        'start_ts': 'inicio_ts',\n",
    "        'weather_conditions': 'clima',\n",
    "        'duration_seconds': 'duracion_s',\n",
    "        'duracion_segundos': 'duracion_s',\n",
    "        'condiciones_climaticas': 'clima',\n",
    "    }\n",
    "    # Renombra solo las que existan, y trabaja sobre una copia\n",
    "    df = df.rename(columns={k: v for k, v in m.items() if k in df.columns}).copy()\n",
    "\n",
    "    # Validación de esquema mínimo\n",
    "    faltan = [c for c in ['inicio_ts', 'clima', 'duracion_s'] if c not in df.columns]\n",
    "    if faltan:\n",
    "        raise ValueError(f\"Faltan columnas: {faltan}. Requiere: inicio_ts, clima, duracion_s.\")\n",
    "\n",
    "    # Cast de tipos robusto\n",
    "    df['inicio_ts']  = pd.to_datetime(df['inicio_ts'], errors='coerce')\n",
    "    df['duracion_s'] = pd.to_numeric(df['duracion_s'], errors='coerce')\n",
    "\n",
    "    # Normaliza 'clima' a dos niveles canónicos\n",
    "    mapa = {\n",
    "        'bad': 'lluvioso', 'lluvioso': 'lluvioso', 'lluvia': 'lluvioso',\n",
    "        'rain': 'lluvioso', 'rainy': 'lluvioso',\n",
    "        'good': 'sin lluvia', 'clear': 'sin lluvia', 'sin lluvia': 'sin lluvia',\n",
    "    }\n",
    "    df['clima'] = (df['clima'].astype('string')\n",
    "                             .str.strip().str.lower()\n",
    "                             .map(mapa)\n",
    "                             .fillna('sin lluvia'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = ren(df)\n",
    "\n",
    "\n",
    "# --- Filtro de plausibilidad y (opcional) atípicos por IQR por grupo ---\n",
    "def out_iqr(s: pd.Series):\n",
    "    \"\"\"\n",
    "    Calcula máscara de atípicos por regla IQR (1.5*IQR) sobre una serie numérica.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    s : pd.Series\n",
    "        Serie numérica (idealmente sin nulos).\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    mask_out : pd.Series[bool]\n",
    "        True en las posiciones consideradas atípicas (outliers).\n",
    "    bounds : tuple[float, float]\n",
    "        Límites (lo, hi) usados para clasificar outliers.\n",
    "    \"\"\"\n",
    "    # Percentiles robustos al orden; asume s ya sin NaN fuera de esta función.\n",
    "    q1, q3 = np.percentile(s, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lo, hi = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    mask_out = (s < lo) | (s > hi)\n",
    "    return mask_out, (lo, hi)\n",
    "\n",
    "\n",
    "# Filtro de plausibilidad duro por duración (MIN_S..MAX_S)\n",
    "sab = df[(df['duracion_s'] >= MIN_S) & (df['duracion_s'] <= MAX_S)].copy()\n",
    "\n",
    "# Remoción opcional de atípicos por grupo de clima\n",
    "if RM_OUT:\n",
    "    partes = []\n",
    "    for lv in ['lluvioso', 'sin lluvia']:\n",
    "        g = sab.loc[sab['clima'].eq(lv), 'duracion_s'].dropna()\n",
    "        if g.empty:\n",
    "            continue\n",
    "        mk, _ = out_iqr(g)\n",
    "        # Conserva solo valores no atípicos y reconstituye la etiqueta de clima\n",
    "        partes.append(pd.DataFrame({'duracion_s': g[~mk], 'clima': lv}))\n",
    "    sab = pd.concat(partes, ignore_index=True) if partes else sab\n",
    "\n",
    "# Resultado filtrado para etapas posteriores\n",
    "df_filtrado = sab.copy()\n",
    "print(\"Dimensiones df_filtrado:\", df_filtrado.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2533de",
   "metadata": {},
   "source": [
    "## 3. Limpieza, validación y reporte reproducible\n",
    "\n",
    "### **Objetivo**  \n",
    "Aplicar reglas mínimas de calidad y plausibilidad para obtener un dataset consistente y trazable, listo para el EDA y las pruebas de hipótesis.\n",
    "\n",
    "### **Qué hace este bloque y por qué**  \n",
    "- **Estandariza esquema y tipos**: usa `ren(...)` para unificar columnas (`inicio_ts`, `clima`, `duracion_s`) y castear a `datetime`/numérico, evitando errores posteriores.  \n",
    "- **Control de nulos y categorías**: descarta filas con nulos en variables clave y restringe `clima` a `{'lluvioso', 'sin lluvia'}` para garantizar comparabilidad.  \n",
    "- **Plausibilidad de duración**: elimina duraciones no válidas (`<= 0 s`) y aplica límites realistas (`MIN_S`, `MAX_S`) para concentrarse en observaciones representativas.  \n",
    "- **Contexto del caso**: se fuerza `dia = 'Sábado'` dado que el análisis se centra en sábados (si el caso cambia, esta asignación debe revisarse).  \n",
    "- **Reporte reproducible**: imprime conteos de nulos, filas eliminadas por cada regla y tamaño final del dataset, facilitando auditoría y trazabilidad.\n",
    "\n",
    "### **Supuestos y alcance**  \n",
    "- Tras `ren(...)`, existen las columnas `inicio_ts`, `clima`, `duracion_s` y sus tipos son correctos.  \n",
    "- Los umbrales `MIN_S`/`MAX_S` reflejan conocimiento del dominio (20–90 min para un trayecto Loop → O'Hare).  \n",
    "- La codificación de `clima` ya está normalizada a dos niveles canónicos.\n",
    "\n",
    "### **Resultados esperados**  \n",
    "- `df_filtrado` listo para EDA y pruebas, con registros válidos y consistentes.  \n",
    "- Un reporte claro de cuántas filas se removieron por nulos, duraciones no válidas y límites realistas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7fdb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Limpieza con reglas realistas y reporte reproducible ---\n",
    "def limpiar_y_validar_datos(df: pd.DataFrame,\n",
    "                            MIN_S: int | None = None,\n",
    "                            MAX_S: int | None = None,\n",
    "                            verbose: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Limpia y valida el dataset aplicando reglas mínimas de calidad y plausibilidad.\n",
    "\n",
    "    Pasos:\n",
    "    1) Estandariza esquema y tipos con `ren(...)` (inicio_ts, clima, duracion_s).\n",
    "    2) Reporta nulos iniciales por columna.\n",
    "    3) Elimina filas con nulos en variables clave y restringe `clima` a\n",
    "       {'lluvioso', 'sin lluvia'} (codificación canónica).\n",
    "    4) Descarta duraciones no válidas (<= 0 s).\n",
    "    5) Aplica filtros realistas opcionales de duración: MIN_S (inferior) y MAX_S (superior).\n",
    "    6) Marca todos los registros como 'Sábado' (variable `dia` forzada para el caso de estudio).\n",
    "    7) Emite un reporte reproducible (si `verbose=True`) con conteos de registros removidos.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Datos de entrada.\n",
    "    MIN_S : int | None\n",
    "        Umbral inferior de duración en segundos. Si None, no se filtra por mínimo.\n",
    "    MAX_S : int | None\n",
    "        Umbral superior de duración en segundos. Si None, no se filtra por máximo.\n",
    "    verbose : bool\n",
    "        Si True, imprime un resumen de validación y limpieza.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame limpio y validado, listo para EDA/pruebas.\n",
    "    \"\"\"\n",
    "    # 1) Estandarización de esquema y tipos\n",
    "    df_clean = ren(df.copy())\n",
    "    n_total = len(df_clean)\n",
    "\n",
    "    # 2) Métricas de calidad iniciales (nulos por variable clave)\n",
    "    stats_iniciales = {\n",
    "        'nulos_ts': df_clean['inicio_ts'].isna().sum(),\n",
    "        'nulos_clima': df_clean['clima'].isna().sum(),\n",
    "        'nulos_duracion': df_clean['duracion_s'].isna().sum()\n",
    "    }\n",
    "\n",
    "    # 3) Eliminación de nulos y normalización de categorías válidas en 'clima'\n",
    "    df_clean = df_clean.dropna(subset=['inicio_ts', 'clima', 'duracion_s'])\n",
    "    df_clean = df_clean[df_clean['clima'].isin(['lluvioso', 'sin lluvia'])]\n",
    "\n",
    "    # 4) Duraciones no válidas (<= 0 s)\n",
    "    mask_negativos = (df_clean['duracion_s'] <= 0) | (df_clean['duracion_s'].isna())\n",
    "    n_negativos = mask_negativos.sum()\n",
    "    df_clean = df_clean[~mask_negativos]\n",
    "\n",
    "    # 5) Filtros realistas de duración (opcional)\n",
    "    n_muy_cortos = 0\n",
    "    n_muy_largos = 0\n",
    "    if MIN_S is not None:\n",
    "        mask_muy_cortos = df_clean['duracion_s'] < MIN_S\n",
    "        n_muy_cortos = mask_muy_cortos.sum()\n",
    "        df_clean = df_clean[~mask_muy_cortos]\n",
    "    if MAX_S is not None:\n",
    "        mask_muy_largos = df_clean['duracion_s'] > MAX_S\n",
    "        n_muy_largos = mask_muy_largos.sum()\n",
    "        df_clean = df_clean[~mask_muy_largos]\n",
    "\n",
    "    # 6) Contexto del caso: todos los registros son sábados (se fuerza 'dia')\n",
    "    #    Nota: si en otro dataset no aplica, quitar o adaptar esta línea.\n",
    "    df_clean['dia'] = 'Sábado'\n",
    "\n",
    "    # Reindex para un índice limpio tras filtrado\n",
    "    df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "    # 7) Reporte reproducible\n",
    "    if verbose:\n",
    "        print(\"=== VALIDACIÓN Y LIMPIEZA DE DATOS ===\")\n",
    "        print('\\n1. CALIDAD DE DATOS INICIAL:')\n",
    "        print(\"-\"*40)\n",
    "        print(f\"Filas totales iniciales: {n_total:,}\")\n",
    "        print(\"Valores nulos iniciales:\")\n",
    "        print(f\"  • inicio_ts: {stats_iniciales['nulos_ts']}\")\n",
    "        print(f\"  • clima: {stats_iniciales['nulos_clima']}\")\n",
    "        print(f\"  • duracion_s: {stats_iniciales['nulos_duracion']}\")\n",
    "\n",
    "        print('\\n2. ELIMINACIÓN DE VALORES ATÍPICOS / INVÁLIDOS:')\n",
    "        print(\"-\"*40)\n",
    "        print(f\"• Duración <= 0 s: {n_negativos}\")\n",
    "        if MIN_S is not None:\n",
    "            print(f\"• Duración < {MIN_S} s: {n_muy_cortos}\")\n",
    "        if MAX_S is not None:\n",
    "            print(f\"• Duración > {MAX_S} s: {n_muy_largos}\")\n",
    "\n",
    "        print('\\n3. RESULTADO FINAL:')\n",
    "        print(\"-\"*40)\n",
    "        print(f\"Filas después de limpieza: {len(df_clean):,}\")\n",
    "        print(f\"Filas correspondientes a sábados (forzado): {len(df_clean):,}\")\n",
    "\n",
    "        print('\\n4. INFORMACIÓN DEL DATASET LIMPIO:')\n",
    "        print(\"-\"*40)\n",
    "        print(f\"Dimensiones: {df_clean.shape}\")\n",
    "        print(f\"Rango de índice: {df_clean.index.min()} - {df_clean.index.max()}\")\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "# Ejecución de la limpieza con los umbrales globales\n",
    "df_limpio = limpiar_y_validar_datos(df, MIN_S=MIN_S, MAX_S=MAX_S, verbose=True)\n",
    "df_limpio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5c51aa",
   "metadata": {},
   "source": [
    "## 4. AED orientado a decisiones\n",
    "\n",
    "### **Objetivo**  \n",
    "Caracterizar, en sábados, la intensidad temporal y la distribución de la duración de viajes por condición climática, para **elegir la prueba estadística adecuada** (paramétrica vs no paramétrica / bootstrap).\n",
    "\n",
    "### **Qué hace este bloque y por qué**  \n",
    "- **Validación de esquema/tipos**: garantiza presencia de `{'dia','inicio_ts','duracion_s','clima'}` y castea a tipos correctos.  \n",
    "- **Filtrado de sábados**: usa `dia` normalizado; si no es confiable, infiere por `weekday` del timestamp.  \n",
    "- **Normalización de clima**: consolida a `{'lluvioso','sin lluvia'}` (`clima_std`) para comparabilidad.  \n",
    "- **Métricas clave**:  \n",
    "  - Intensidad: viajes por **fecha** y por **hora** (picos/vales).  \n",
    "  - Duración: media, mediana, rango, DE y **CV**.  \n",
    "  - Por clima: conteo, porcentaje y media de duración.  \n",
    "  - Forma: **sesgo** y **curtosis** para detectar asimetrías/colas.  \n",
    "- **Visualizaciones (2×3)**:  \n",
    "  a) Serie temporal por clima (conteo diario).  \n",
    "  b) Viajes por hora (barras).  \n",
    "  c) Viajes por clima (barras).  \n",
    "  d) Duración promedio por hora (línea).  \n",
    "  e) Histogramas por clima.  \n",
    "  f) Boxplot por clima.\n",
    "\n",
    "### **Criterios para elegir la prueba**  \n",
    "- Distribuciones similares y sin colas extremas --> **t de Student** (Welch si varianzas desiguales).  \n",
    "- Asimetría marcada, colas pesadas o tamaños muy distintos --> **Mann–Whitney** o **bootstrap** (diferencia de medias/medianas).\n",
    "\n",
    "### **Supuestos y alcance**  \n",
    "- `df_clean` ya fue sometido a limpieza/validación previa.  \n",
    "- La asignación a sábados es coherente con el objetivo del estudio.\n",
    "\n",
    "### **Resultados esperados**  \n",
    "- Panorama claro de intensidad temporal y forma de la distribución por clima.  \n",
    "- Evidencia visual/numérica para sustentar la elección de la prueba estadística en la siguiente sección.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Exploratorio orientado a decisiones — guía la prueba a usar ---\n",
    "def aed(df_clean: pd.DataFrame, GRAF: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Realiza un EDA compacto, enfocado en decidir la prueba estadística adecuada\n",
    "    para comparar la duración de viajes en sábado según la condición climática.\n",
    "\n",
    "    Flujo:\n",
    "    1) Validación de esquema mínimo y tipado robusto.\n",
    "    2) Normalización de 'dia' para asegurar el subconjunto de sábados.\n",
    "       - Si 'dia' no es confiable, se usa el día de la semana de 'inicio_ts'.\n",
    "    3) Normalización de clima a {'lluvioso', 'sin lluvia'} en 'clima_std'.\n",
    "    4) Métricas clave:\n",
    "       - Intensidad temporal (viajes por fecha/hora).\n",
    "       - Estadísticos de duración (media, mediana, rango, DE, CV).\n",
    "       - Resumen por clima (n, %, media).\n",
    "       - Forma de la distribución (sesgo, curtosis).\n",
    "    5) Visualizaciones (2×3) si GRAF=True:\n",
    "       a) Serie temporal: conteo diario por clima.\n",
    "       b) Viajes por hora.\n",
    "       c) Viajes por clima.\n",
    "       d) Duración promedio por hora.\n",
    "       e) Histogramas de duración por clima.\n",
    "       f) Boxplot de duración por clima.\n",
    "\n",
    "    Decisión estadística (orientativa):\n",
    "    - Si las distribuciones por clima son similares y sin colas extremas → t de Student\n",
    "      (con Welch si varianzas desiguales).\n",
    "    - Si hay asimetría/colas o tamaños muy distintos → prueba no paramétrica\n",
    "      (Mann–Whitney) o bootstrap de diferencia de medias/medianas.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df_clean : pd.DataFrame\n",
    "        Dataset ya limpiado/validado con al menos las columnas:\n",
    "        {'dia','inicio_ts','duracion_s','clima'}.\n",
    "    GRAF : bool\n",
    "        Si True, genera figura con 6 subplots; si False, solo imprime métricas.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    None\n",
    "        Imprime resultados y, si procede, dibuja figuras.\n",
    "    \"\"\"\n",
    "    # Chequeos y normalizaciones básicas\n",
    "    req = {'dia', 'inicio_ts', 'duracion_s', 'clima'}\n",
    "    missing = req - set(df_clean.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Faltan columnas requeridas: {sorted(missing)}\")\n",
    "\n",
    "    df = df_clean.copy()\n",
    "\n",
    "    # Asegurar datetime y numérico; descartar nulos críticos\n",
    "    df['inicio_ts']  = pd.to_datetime(df['inicio_ts'], errors='coerce')\n",
    "    df['duracion_s'] = pd.to_numeric(df['duracion_s'], errors='coerce')\n",
    "    df = df.dropna(subset=['inicio_ts', 'duracion_s'])\n",
    "\n",
    "    # Normalizar 'dia' (ej. 'Sábado'/'sabado'/'Saturday' -> 'sabado')\n",
    "    dia_norm = (df['dia'].astype(str)\n",
    "                .str.normalize('NFKD').str.encode('ascii', 'ignore').str.decode('utf-8')\n",
    "                .str.lower().str.strip())\n",
    "    df['dia_norm'] = dia_norm\n",
    "\n",
    "    # Subconjunto de sábados; si no hay, inferir por weekday (5 = sábado)\n",
    "    sab = df[df['dia_norm'].eq('sabado')].copy()\n",
    "    if sab.empty:\n",
    "        sab = df[df['inicio_ts'].dt.dayofweek.eq(5)].copy()\n",
    "        if sab.empty:\n",
    "            raise RuntimeError(\"No hay registros de sábado. Revisa 'dia' o el dtype de 'inicio_ts'.\")\n",
    "\n",
    "    # Normalizar clima a {'lluvioso','sin lluvia'} conservando valores originales si no mapean\n",
    "    clima_map = {\n",
    "        'lluvioso': 'lluvioso', 'con lluvia': 'lluvioso', 'rainy': 'lluvioso',\n",
    "        'sin lluvia': 'sin lluvia', 'no lluvioso': 'sin lluvia', 'not rainy': 'sin lluvia', 'seco': 'sin lluvia'\n",
    "    }\n",
    "    sab['clima_std'] = (sab['clima'].astype(str).str.lower().str.strip().map(clima_map)\n",
    "                        .fillna(sab['clima'].astype(str)))\n",
    "\n",
    "    # --- Métricas impresas (EDA numérico) ---\n",
    "    print(\"=\"*60)\n",
    "    print(\"ANÁLISIS EXPLORATORIO DE DATOS: Viajes en Sábado (Loop → O'Hare)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 1) Análisis temporal\n",
    "    print(\"\\n1. ANÁLISIS TEMPORAL\")\n",
    "    print(\"-\"*40)\n",
    "    viajes_por_fecha = sab.groupby(sab['inicio_ts'].dt.date).size()\n",
    "    print(f\"• Viajes por día: {viajes_por_fecha.mean():.1f} ± {viajes_por_fecha.std():.1f}\")\n",
    "    print(f\"• Rango: {viajes_por_fecha.min()} - {viajes_por_fecha.max()} viajes/día\")\n",
    "    viajes_por_hora = sab.groupby(sab['inicio_ts'].dt.hour).size()\n",
    "    print(f\"• Hora pico: {viajes_por_hora.idxmax()}:00 hrs ({viajes_por_hora.max()} viajes)\")\n",
    "    print(f\"• Horas valle: {viajes_por_hora.idxmin()}:00 hrs ({viajes_por_hora.min()} viajes)\")\n",
    "\n",
    "    # 2) Estadísticos de duración\n",
    "    print(\"\\n2. ANÁLISIS DE DURACIÓN\")\n",
    "    print(\"-\"*40)\n",
    "    dsc = sab['duracion_s'].describe()\n",
    "    mean = dsc['mean']; std = dsc['std']\n",
    "    print(f\"• Promedio: {mean/60:.1f} min | Mediana: {dsc['50%']/60:.1f} min\")\n",
    "    print(f\"• Rango: {dsc['min']/60:.1f} - {dsc['max']/60:.1f} min | DE: {std/60:.1f} min\")\n",
    "    cv = (std/mean)*100 if mean != 0 else np.nan\n",
    "    print(f\"• CV: {cv:.1f}%\")\n",
    "\n",
    "    # 3) Resumen por clima\n",
    "    print(\"\\n3. ANÁLISIS POR CONDICIÓN CLIMÁTICA\")\n",
    "    print(\"-\"*40)\n",
    "    clima_counts = sab['clima_std'].value_counts()\n",
    "    clima_duration = sab.groupby('clima_std')['duracion_s'].agg(['mean', 'std', 'count'])\n",
    "    for c in clima_counts.index:\n",
    "        count = clima_counts[c]\n",
    "        percent = (count / len(sab)) * 100\n",
    "        mean_dur = clima_duration.loc[c, 'mean'] / 60\n",
    "        print(f\"• {c.title()}: {count} viajes ({percent:.1f}%), {mean_dur:.1f} min promedio\")\n",
    "\n",
    "    # 4) Forma de la distribución\n",
    "    print(\"\\n4. ESTADÍSTICAS DE DISTRIBUCIÓN\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"• Sesgo: {sab['duracion_s'].skew():.3f} | Kurtosis: {sab['duracion_s'].kurt():.3f}\")\n",
    "\n",
    "    # --- Visualizaciones ---\n",
    "    if not GRAF:\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "    # a) Serie temporal: días lluviosos vs secos por fecha (sin crear columnas nuevas)\n",
    "    sab['inicio_ts'] = pd.to_datetime(sab['inicio_ts'], errors='coerce')\n",
    "    sab_ok = sab.dropna(subset=['inicio_ts'])\n",
    "    freq = (pd.crosstab(\n",
    "                sab_ok['inicio_ts'].dt.normalize(),   # fecha (00:00)\n",
    "                sab_ok['clima_std']                    # categorías normalizadas\n",
    "            )\n",
    "            .reindex(columns=['sin lluvia', 'lluvioso'], fill_value=0)\n",
    "            .sort_index())\n",
    "\n",
    "    axes[0,0].plot(freq.index, freq['sin lluvia'].to_numpy(), marker='o', linewidth=2, label='Sin lluvia')\n",
    "    axes[0,0].plot(freq.index, freq['lluvioso'].to_numpy(),   marker='o', linewidth=2, label='Lluvioso')\n",
    "    axes[0,0].set_title('Días Lluviosos vs Secos por Fecha')\n",
    "    axes[0,0].set_xlabel('Fecha'); axes[0,0].set_ylabel('Frecuencia')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    axes[0,0].legend(title='Clima')\n",
    "\n",
    "    # b) Viajes por hora (barras)\n",
    "    axes[0,1].bar(viajes_por_hora.index, viajes_por_hora.values, alpha=0.7)\n",
    "    axes[0,1].set_title(\"Viajes por hora (Sábados)\")\n",
    "    axes[0,1].set_xlabel(\"Hora\"); axes[0,1].set_ylabel(\"Cantidad de viajes\")\n",
    "    axes[0,1].set_xticks(range(0, 24, 2))\n",
    "    axes[0,1].grid(True, axis='y', lw=0.5, alpha=0.6)\n",
    "\n",
    "    # c) Viajes por clima (barras)\n",
    "    viajes_por_clima = sab['clima_std'].value_counts()\n",
    "    axes[0,2].bar(viajes_por_clima.index, viajes_por_clima.values, alpha=0.7)\n",
    "    axes[0,2].set_title(\"Viajes por condición climática (Sábados)\")\n",
    "    axes[0,2].set_ylabel(\"Cantidad de viajes\")\n",
    "\n",
    "    # d) Duración promedio por hora (línea)\n",
    "    duracion_por_hora = sab.groupby(sab['inicio_ts'].dt.hour)['duracion_s'].mean()\n",
    "    axes[1,0].plot(duracion_por_hora.index, duracion_por_hora.values, marker='o', linewidth=2)\n",
    "    axes[1,0].set_title(\"Duración promedio por hora (Sábados)\")\n",
    "    axes[1,0].set_xlabel(\"Hora\"); axes[1,0].set_ylabel(\"Duración promedio (s)\")\n",
    "    axes[1,0].set_xticks(range(0, 24, 2))\n",
    "    axes[1,0].grid(True, lw=0.5, alpha=0.6)\n",
    "\n",
    "    # e) Histogramas por clima\n",
    "    a = sab.loc[sab['clima_std'].eq('sin lluvia'), 'duracion_s'].astype(float).values\n",
    "    b = sab.loc[sab['clima_std'].eq('lluvioso'),    'duracion_s'].astype(float).values\n",
    "    axes[1,1].hist(a, bins=30, alpha=0.6, label=\"Sin lluvia\")\n",
    "    axes[1,1].hist(b, bins=30, alpha=0.6, label=\"Lluvioso\")\n",
    "    axes[1,1].set_title(\"Sábado: histograma de duración por clima\")\n",
    "    axes[1,1].set_xlabel(\"Duración (s)\"); axes[1,1].set_ylabel(\"Frecuencia\")\n",
    "    axes[1,1].legend(); axes[1,1].grid(True, lw=0.5, alpha=0.6)\n",
    "\n",
    "    # f) Boxplot por clima (completa 2×3)\n",
    "    sab.boxplot(column='duracion_s', by='clima_std', ax=axes[1,2])\n",
    "    axes[1,2].set_title(\"Duración por clima (boxplot)\")\n",
    "    axes[1,2].set_xlabel(\"\"); axes[1,2].set_ylabel(\"Duración (s)\")\n",
    "    fig.suptitle(\"\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Ejemplo de uso (si tu DataFrame limpio se llama df_limpio):\n",
    "aed(df_limpio, GRAF=GRAF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec9837",
   "metadata": {},
   "source": [
    "## 5. Utilidades: normalidad, tamaños de efecto e IC bootstrap\n",
    "\n",
    "### **Objetivo**  \n",
    "Proveer funciones reutilizables para: (i) evaluar **normalidad** de las muestras, (ii) calcular **tamaños de efecto** comparables (g de Hedges) y (iii) estimar **intervalos de confianza bootstrap** (medias y medianas) para diferencias entre grupos.\n",
    "\n",
    "### **Qué hace este bloque y por qué**  \n",
    "- **`pnorm`**: aplica una prueba de normalidad adaptativa al tamaño muestral (Shapiro–Wilk hasta n=500; D’Agostino–Pearson en n grandes). Evita conclusiones débiles en n<8 devolviendo 1.0.  \n",
    "- **`g_hedges`**: estima el tamaño de efecto para dos grupos independientes corrigiendo el sesgo de `d` en muestras finitas; devuelve `NaN` si no hay grados de libertad y 0 si la DE agrupada es 0.  \n",
    "- **`ci_boot_means` / `ci_boot_medians`**: generan IC del 95% por percentiles para la diferencia de medias/medianas usando remuestreo con reemplazo y semilla reproducible (`RNG_SEED`).  \n",
    "\n",
    "### **Supuestos y alcance**  \n",
    "- Las entradas (`x`, `y`) son arrays numéricos independientes por grupo y sin NaN.  \n",
    "- Los IC bootstrap reflejan la variabilidad muestral bajo remuestreo con reemplazo; no asumen normalidad.  \n",
    "- Para tamaños de muestra muy pequeños (n<8), los tests de normalidad son poco informativos.\n",
    "\n",
    "### **Resultados esperados**  \n",
    "- p-valores de normalidad coherentes con el tamaño muestral.  \n",
    "- Tamaños de efecto **g** interpretables (pequeño ~0.2, mediano ~0.5, grande ~0.8, guía orientativa).  \n",
    "- IC 95% (medias/medianas) listos para reporte y para acompañar la prueba de hipótesis principal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c831b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utilidades de normalidad y tamaños de efecto ---\n",
    "def pnorm(a: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Devuelve el p-valor de una prueba de normalidad adecuada al tamaño muestral.\n",
    "    \n",
    "    Reglas:\n",
    "    - n < 8  → devuelve 1.0 (no hay potencia para testear normalidad).\n",
    "    - 8 ≤ n ≤ 500  → Shapiro–Wilk (potente en muestras pequeñas/medianas).\n",
    "    - n > 500 → D’Agostino–Pearson (stats.normaltest), más estable en n grandes.\n",
    "    \"\"\"\n",
    "    a = np.asarray(a, float)\n",
    "    n = a.size\n",
    "    if n < 8:\n",
    "        return 1.0\n",
    "    return stats.shapiro(a).pvalue if n <= 500 else stats.normaltest(a).pvalue\n",
    "\n",
    "\n",
    "def g_hedges(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el tamaño de efecto g de Hedges para dos grupos independientes.\n",
    "\n",
    "    g corrige el sesgo de Cohen's d en muestras finitas:\n",
    "        g = J * d,  con  J = 1 - 3/(4*(n1+n2) - 9)\n",
    "\n",
    "    Retorna NaN si algún grupo tiene n < 2; retorna 0 si la DE agrupada es 0.\n",
    "    \"\"\"\n",
    "    x, y = np.asarray(x, float), np.asarray(y, float)\n",
    "    n1, n2 = len(x), len(y)\n",
    "    if n1 < 2 or n2 < 2:\n",
    "        return np.nan\n",
    "\n",
    "    s1, s2 = x.var(ddof=1), y.var(ddof=1)\n",
    "    df_pooled = (n1 + n2 - 2)\n",
    "    if df_pooled <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    # DE agrupada (pooled)\n",
    "    sp = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / df_pooled)\n",
    "    if not np.isfinite(sp) or sp == 0:\n",
    "        return 0.0\n",
    "\n",
    "    d = (x.mean() - y.mean()) / sp\n",
    "    J = 1 - 3 / (4 * (n1 + n2) - 9) if (n1 + n2) > 2 else 1.0\n",
    "    return J * d\n",
    "\n",
    "\n",
    "def ci_boot_means(x: np.ndarray, y: np.ndarray, B: int = NBOOT, seed: int = RNG_SEED) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    IC bootstrap (percentil) del 95% para la diferencia de medias (x - y).\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    x, y : arrays numéricos\n",
    "    B : int\n",
    "        Número de réplicas bootstrap.\n",
    "    seed : int\n",
    "        Semilla para reproducibilidad.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    (lo, hi) : tupla de floats\n",
    "        Límites inferior y superior del IC al 95% por percentiles (2.5, 97.5).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x, y = np.asarray(x, float), np.asarray(y, float)\n",
    "    n1, n2 = len(x), len(y)\n",
    "    dif = np.empty(B)\n",
    "\n",
    "    for b in range(B):\n",
    "        dif[b] = rng.choice(x, n1, True).mean() - rng.choice(y, n2, True).mean()\n",
    "\n",
    "    lo, hi = np.percentile(dif, [2.5, 97.5])\n",
    "    return lo, hi\n",
    "\n",
    "\n",
    "def ci_boot_medians(x: np.ndarray, y: np.ndarray, B: int = NBOOT, seed: int = RNG_SEED) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    IC bootstrap (percentil) del 95% para la diferencia de medianas (x - y).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)  # semilla una sola vez\n",
    "    x, y = np.asarray(x, float), np.asarray(y, float)\n",
    "    n1, n2 = len(x), len(y)\n",
    "    dif = np.empty(B)\n",
    "\n",
    "    for b in range(B):\n",
    "        xb = rng.choice(x, size=n1, replace=True)\n",
    "        yb = rng.choice(y, size=n2, replace=True)\n",
    "        dif[b] = np.median(xb) - np.median(yb)\n",
    "\n",
    "    lo, hi = np.percentile(dif, [2.5, 97.5])\n",
    "    return lo, hi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20762479",
   "metadata": {},
   "source": [
    "## 6. Supuestos, prueba de dos grupos y tamaños de efecto\n",
    "\n",
    "### **Objetivo**  \n",
    "Contrastar la **duración** de viajes en sábado entre **lluvioso** y **sin lluvia**, verificando supuestos (normalidad y varianzas) y reportando evidencia completa: prueba seleccionada, p-valor, tamaño de efecto e IC bootstrap.\n",
    "\n",
    "### **Qué hace este bloque y por qué**  \n",
    "- **Limpieza opcional de outliers** por IQR dentro de cada clima para no sesgar la comparación.  \n",
    "- **Normalidad adaptativa** (`pnorm`) y **Levene** (centro=mediana) para decidir entre:  \n",
    "  - **t de Student** (Welch si varianzas desiguales) cuando ambas muestras parecen normales.  \n",
    "  - **Mann–Whitney U** cuando no se cumple normalidad.  \n",
    "- **Intervalos de confianza bootstrap (95%)** para la diferencia (medias o medianas), y **tamaño de efecto**:  \n",
    "  - `g` de Hedges en el caso paramétrico.  \n",
    "  - `r` derivado de U→z en el caso no paramétrico.  \n",
    "- **Salida estructurada** con diferencia puntual en minutos, IC, p-valor, estadístico y N por grupo.\n",
    "\n",
    "### **Supuestos y alcance**  \n",
    "- `df_limpio` ya contiene solo sábados y `clima ∈ {lluvioso, sin lluvia}`.  \n",
    "- Bootstrap asume remuestreo independiente por grupo.  \n",
    "- La interpretación de tamaños de efecto sigue guías orientativas (p.ej., g≈0.2 pequeño, 0.5 mediano, 0.8 grande).\n",
    "\n",
    "### **Resultados esperados**  \n",
    "- Decisión clara sobre la prueba empleada (t/Welch vs Mann–Whitney).  \n",
    "- Evidencia cuantitativa completa: **diferencia en minutos**, **IC 95%**, **p-valor** y **tamaño de efecto** lista para el informe final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe83376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prueba de hipótesis con árbol de decisión + tamaños de efecto ---\n",
    "def verificar_supuestos_y_prueba(df_clean: pd.DataFrame,\n",
    "                                 alpha: float = ALFA,\n",
    "                                 rm_outliers: bool = RM_OUT) -> dict:\n",
    "    \"\"\"\n",
    "    Verifica supuestos (normalidad/varianzas) y ejecuta una prueba de dos grupos\n",
    "    para comparar duración en sábado por clima: 'lluvioso' vs 'sin lluvia'.\n",
    "\n",
    "    Árbol de decisión:\n",
    "    - Si ambas muestras pasan normalidad (p>α) → t-test (Welch si varianzas desiguales).\n",
    "    - En otro caso → Mann–Whitney U (no paramétrica).\n",
    "    Además, reporta tamaños de efecto (g de Hedges o r) e IC bootstrap (medias o medianas).\n",
    "\n",
    "    Retorna un diccionario con la prueba usada, p-valor, estadístico,\n",
    "    diferencia puntual en minutos, IC al 95% en minutos, tamaños muestrales y efecto.\n",
    "    \"\"\"\n",
    "    sab = df_clean.copy()  # todos son 'Sábado' post-limpieza\n",
    "    if sab.empty:\n",
    "        raise RuntimeError(\"Dataset vacío tras la limpieza.\")\n",
    "\n",
    "    # (Opcional) quitar atípicos por IQR dentro de cada nivel de clima\n",
    "    if rm_outliers:\n",
    "        sab_f = []\n",
    "        for lv in ['lluvioso', 'sin lluvia']:\n",
    "            g = sab[sab['clima'].eq(lv)].copy()\n",
    "            if g.empty:\n",
    "                continue\n",
    "            mk, _ = out_iqr(g['duracion_s'])\n",
    "            sab_f.append(g.loc[~mk])\n",
    "        sab = pd.concat(sab_f, ignore_index=True) if sab_f else sab\n",
    "\n",
    "    # Definir grupos (en segundos)\n",
    "    grupo_lluvioso   = sab.loc[sab['clima'].eq('lluvioso'),   'duracion_s'].astype(float).values\n",
    "    grupo_sin_lluvia = sab.loc[sab['clima'].eq('sin lluvia'), 'duracion_s'].astype(float).values\n",
    "    n_ll, n_sl = len(grupo_lluvioso), len(grupo_sin_lluvia)\n",
    "    if n_ll < 2 or n_sl < 2:\n",
    "        raise RuntimeError(\"Tamaño de muestra insuficiente para realizar pruebas estadísticas.\")\n",
    "\n",
    "    print(\"=\"*38)\n",
    "    print(\"VERIFICACIÓN DE SUPUESTOS ESTADÍSTICOS\")\n",
    "    print(\"=\"*38)\n",
    "\n",
    "    # 1) Normalidad\n",
    "    print(\"\\n1. PRUEBAS DE NORMALIDAD:\")\n",
    "    print(\"-\"*27)\n",
    "    p_norm_ll = pnorm(grupo_lluvioso)\n",
    "    p_norm_sl = pnorm(grupo_sin_lluvia)\n",
    "    print(f\"  Lluvioso    → p={p_norm_ll:.4g}\")\n",
    "    print(f\"  Sin lluvia  → p={p_norm_sl:.4g}\")\n",
    "\n",
    "    # 2) Homogeneidad de varianzas (Levene con centro en la mediana = robusto)\n",
    "    p_var = stats.levene(grupo_lluvioso, grupo_sin_lluvia, center='median').pvalue\n",
    "    print(\"\\n2. IGUALDAD DE VARIANZAS (Levene, centro=mediana):\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"  p={p_var:.4g}\")\n",
    "\n",
    "    # 3) Selección de prueba\n",
    "    use_mean = (p_norm_ll > alpha) and (p_norm_sl > alpha)\n",
    "    if use_mean:\n",
    "        print(\"\\n3. PRUEBA: medias (t de Student/Welch)\")\n",
    "        equal_var = p_var > alpha\n",
    "        stat, p_valor = stats.ttest_ind(grupo_lluvioso, grupo_sin_lluvia, equal_var=equal_var)\n",
    "        tam = g_hedges(grupo_lluvioso, grupo_sin_lluvia)  # tamaño de efecto\n",
    "        dif_obs = grupo_lluvioso.mean() - grupo_sin_lluvia.mean()\n",
    "        lo, hi  = ci_boot_means(grupo_lluvioso, grupo_sin_lluvia, B=NBOOT, seed=RNG_SEED)\n",
    "        stat_name = \"media\"\n",
    "        interpret = (\"pequeño\" if abs(tam) < 0.2 else\n",
    "                     \"pequeño–moderado\" if abs(tam) < 0.5 else\n",
    "                     \"moderado\" if abs(tam) < 0.8 else \"grande\")\n",
    "        punto_est = dif_obs / 60\n",
    "        lo_m, hi_m = lo / 60, hi / 60\n",
    "    else:\n",
    "        print(\"\\n3. PRUEBA: medianas (Mann–Whitney U)\")\n",
    "        stat, p_valor = stats.mannwhitneyu(grupo_lluvioso, grupo_sin_lluvia, alternative='two-sided')\n",
    "        dif_obs = np.median(grupo_lluvioso) - np.median(grupo_sin_lluvia)\n",
    "        lo, hi  = ci_boot_medians(grupo_lluvioso, grupo_sin_lluvia, B=NBOOT, seed=RNG_SEED)\n",
    "        # Tamaño de efecto r desde U → z estandarizado\n",
    "        n_ll, n_sl = len(grupo_lluvioso), len(grupo_sin_lluvia)\n",
    "        mu = n_ll * n_sl / 2\n",
    "        sigma = np.sqrt(n_ll * n_sl * (n_ll + n_sl + 1) / 12)\n",
    "        z = (stat - mu) / sigma\n",
    "        tam = abs(z) / np.sqrt(n_ll + n_sl)\n",
    "        stat_name = \"mediana\"\n",
    "        interpret = None\n",
    "        punto_est = dif_obs / 60\n",
    "        lo_m, hi_m = lo / 60, hi / 60\n",
    "\n",
    "    # 4) Reporte de resultados\n",
    "    print(\"\\n4. RESULTADOS:\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"• Diferencia de {stat_name}s (min): {punto_est:+.2f}\")\n",
    "    print(f\"• IC {int((1-ALFA)*100)}% (min): [{lo_m:.2f}, {hi_m:.2f}]\")\n",
    "    print(f\"• Estadístico: {stat:.3f} | p-valor: {p_valor:.4g}\")\n",
    "    if use_mean:\n",
    "        print(f\"• Tamaño de efecto (g de Hedges): {tam:.3f} ({interpret})\")\n",
    "    else:\n",
    "        print(f\"• Tamaño de efecto (r de Mann-Whitney): {tam:.3f}\")\n",
    "\n",
    "    concl = (\"Diferencia estadísticamente significativa\"\n",
    "             if p_valor < alpha else\n",
    "             \"No se encontró diferencia estadísticamente significativa\")\n",
    "    print(f\"• Conclusión: {concl} (α={alpha})\")\n",
    "\n",
    "    # Salida estructurada para uso posterior (tablas/figuras/reporte)\n",
    "    return {\n",
    "        'prueba': 't (Student/Welch)' if use_mean else 'Mann–Whitney U',\n",
    "        'p_valor': float(p_valor),\n",
    "        'estadistico': float(stat),\n",
    "        'use_mean': use_mean,\n",
    "        'dif_minutos': float(punto_est),\n",
    "        'ic_minutos': (float(lo_m), float(hi_m)),\n",
    "        'n_lluvioso': int(len(grupo_lluvioso)),\n",
    "        'n_sin_lluvia': int(len(grupo_sin_lluvia)),\n",
    "        'tam_efecto': float(tam),\n",
    "        'tipo_efecto': 'g_hedges' if use_mean else 'r_mannwhitney'\n",
    "    }\n",
    "\n",
    "\n",
    "# Ejecutar (usa los flags globales definidos previamente)\n",
    "resultados_prueba = verificar_supuestos_y_prueba(df_limpio, alpha=ALFA, rm_outliers=RM_OUT)\n",
    "resultados_prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc4c3a8",
   "metadata": {},
   "source": [
    "## 7. Comparación visual (violín + box + jitter) con énfasis en media/mediana\n",
    "\n",
    "### **Objetivo**  \n",
    "Ofrecer una comparación **intuitiva y robusta** de la distribución de la duración entre **lluvioso** y **sin lluvia**, resaltando el estadístico central (media o mediana) coherente con la prueba inferencial seleccionada.\n",
    "\n",
    "### **Qué hace este bloque y por qué**  \n",
    "- **Violín**: revela la **forma** de la distribución (asimetrías, multimodalidad, colas).  \n",
    "- **Boxplot**: resume **mediana** e **IQR**, complementando la lectura del violín.  \n",
    "- **Jitter**: muestra la **dispersión puntual** y sugiere el **tamaño muestral** (se añade además `n` bajo las categorías).  \n",
    "- **IQR por grupo (opcional)**: si `rm_outliers=True`, elimina atípicos extremos dentro de cada clima (1.5·IQR), evitando que pocos valores extremos dominen la percepción.  \n",
    "- **Coherencia inferencial**: el marcador central resalta **mediana** (Mann–Whitney) o **media** (t/Welch), armonizando visual y prueba.\n",
    "\n",
    "### **Supuestos y alcance**  \n",
    "- `df_limpio` contiene `duracion_s` (segundos) y `clima ∈ {lluvioso, sin lluvia}`.  \n",
    "- El filtrado por IQR aquí es **visual/diagnóstico** y se declara por separado en la sección inferencial.  \n",
    "- Si un grupo queda sin datos (p. ej., tras filtros), la función evita fallos y avisa.\n",
    "\n",
    "### **Resultados esperados**  \n",
    "- Una lectura visual clara de **posición**, **dispersión** y **forma** por clima, con el estadístico central resaltado según la prueba.  \n",
    "- Contexto de **tamaño muestral** por grupo (etiquetas `n=`), útil para interpretar densidad vs. variabilidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5769a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparacion_visual_violin_box_jitter(\n",
    "    df_limpio: pd.DataFrame,\n",
    "    rm_outliers: bool = True,\n",
    "    seed: int = RNG_SEED,\n",
    "    use_mean: bool | None = None,\n",
    "    resultados: dict | None = None,\n",
    "    color_ll: str = \"blue\",\n",
    "    color_sl: str = \"orange\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Visualización robusta de 'duracion_s' por clima ('lluvioso' vs 'sin lluvia'):\n",
    "      • Violín: forma/densidad de la distribución.\n",
    "      • Boxplot: mediana e IQR (sin outliers si ya filtramos por IQR).\n",
    "      • Jitter: dispersión puntual (muestra N y variabilidad).\n",
    "      • Marcador central: resalta MEDIA o MEDIANA según `use_mean` o `resultados`.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    df_limpio : pd.DataFrame\n",
    "        Dataset limpio (solo sábados) con columnas 'duracion_s' (numérico) y 'clima'.\n",
    "    rm_outliers : bool\n",
    "        Si True, remueve atípicos por la regla 1.5·IQR **por grupo de clima**.\n",
    "    seed : int\n",
    "        Semilla para reproducibilidad del jitter (ruido horizontal).\n",
    "    use_mean : bool | None\n",
    "        Si True, resalta **media**; si False, **mediana**. Si None, toma de `resultados['use_mean']`\n",
    "        (por ejemplo, coherente con t-test vs Mann–Whitney); por defecto False (mediana).\n",
    "    resultados : dict | None\n",
    "        Diccionario opcional (salida de `verificar_supuestos_y_prueba`) para inferir `use_mean`.\n",
    "    color_ll : str\n",
    "        Color para el grupo 'lluvioso'.\n",
    "    color_sl : str\n",
    "        Color para el grupo 'sin lluvia'.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    None\n",
    "        Dibuja la figura en pantalla.\n",
    "    \"\"\"\n",
    "    # 1) Elegir estadístico central a resaltar\n",
    "    if use_mean is None:\n",
    "        use_mean = bool(resultados.get('use_mean', False)) if isinstance(resultados, dict) else False\n",
    "\n",
    "    # 2) Preparación de datos y tipos\n",
    "    sab = (\n",
    "        df_limpio[[\"duracion_s\", \"clima\"]]\n",
    "        .copy()\n",
    "        .assign(duracion_s=lambda d: pd.to_numeric(d[\"duracion_s\"], errors=\"coerce\"))\n",
    "        .dropna(subset=[\"duracion_s\", \"clima\"])\n",
    "    )\n",
    "\n",
    "    # 3) Filtrado IQR por grupo (opcional)\n",
    "    if rm_outliers and not sab.empty:\n",
    "        def _keep(s: pd.Series) -> pd.Series:\n",
    "            q1, q3 = s.quantile([0.25, 0.75])\n",
    "            iqr = q3 - q1\n",
    "            lo, hi = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "            return s.between(lo, hi)\n",
    "\n",
    "        sab = sab.loc[sab.groupby(\"clima\")[\"duracion_s\"].transform(_keep)]\n",
    "\n",
    "    # 4) Extraer arrays por grupo (en segundos, consistente con análisis)\n",
    "    vals_ll = sab.loc[sab[\"clima\"].eq(\"lluvioso\"), \"duracion_s\"].to_numpy(float)\n",
    "    vals_sl = sab.loc[sab[\"clima\"].eq(\"sin lluvia\"), \"duracion_s\"].to_numpy(float)\n",
    "    datos   = [vals_ll, vals_sl]\n",
    "    ns      = [vals_ll.size, vals_sl.size]\n",
    "\n",
    "    # 5) Manejo robusto si falta alguno de los grupos\n",
    "    if ns[0] == 0 and ns[1] == 0:\n",
    "        print(\"Sin datos para graficar después de filtros.\")\n",
    "        return\n",
    "\n",
    "    # 6) Figura\n",
    "    fig, ax = plt.subplots(figsize=(8, 5), constrained_layout=True)\n",
    "\n",
    "    # Violines (sin extremos para no duplicar con boxplot)\n",
    "    vp = ax.violinplot(datos, showmeans=False, showextrema=False)\n",
    "    for i, body in enumerate(vp.get(\"bodies\", []), start=1):\n",
    "        body.set_facecolor(color_ll if i == 1 else color_sl)\n",
    "        body.set_edgecolor(\"black\")\n",
    "        body.set_alpha(0.28)\n",
    "\n",
    "    # Boxplots (sin mostrar outliers porque ya controlamos IQR)\n",
    "    bp = ax.boxplot(\n",
    "        datos,\n",
    "        showfliers=False,\n",
    "        patch_artist=True,\n",
    "        medianprops=dict(color=\"red\", linewidth=1.4),\n",
    "    )\n",
    "    for box in bp[\"boxes\"]:\n",
    "        box.set_facecolor(\"white\")\n",
    "        box.set_linewidth(1.3)\n",
    "\n",
    "    # Jitter: puntos individuales (da sensación de N y dispersión)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for i, arr in enumerate(datos, start=1):\n",
    "        if arr.size == 0:\n",
    "            continue\n",
    "        x = rng.normal(loc=i, scale=0.05, size=arr.size)\n",
    "        ax.plot(x, arr, \"o\", ms=2.2, alpha=0.22, color=(color_ll if i == 1 else color_sl))\n",
    "\n",
    "    # Marcador central (media o mediana)\n",
    "    stat_vals = [(a.mean() if use_mean else np.median(a)) if a.size else np.nan for a in datos]\n",
    "    ax.scatter(\n",
    "        [1, 2], stat_vals,\n",
    "        marker=\"o\", s=30, c=\"red\", edgecolors=\"red\", linewidths=1.2, zorder=3,\n",
    "        label=(\"Media\" if use_mean else \"Mediana\"),\n",
    "    )\n",
    "\n",
    "    # Ejes y estilo\n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels([\"Lluvioso\", \"Sin lluvia\"])\n",
    "    ax.set_title(\"Sábado: Duración por clima\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Clima\")\n",
    "    ax.set_ylabel(\"Duración (s)\")\n",
    "    ax.grid(True, lw=0.6, alpha=0.55, axis=\"y\")\n",
    "    ax.legend(frameon=False, loc=\"upper right\")\n",
    "\n",
    "    # Formato es-MX del eje Y si el formateador está disponible\n",
    "    try:\n",
    "        ax.yaxis.set_major_formatter(FuncFormatter(fmt_miles_es))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 7) Contexto adicional en eje X: n por grupo (ayuda a leer densidad)\n",
    "    for i, n in enumerate(ns, start=1):\n",
    "        ax.text(i, ax.get_ylim()[0], f\"n={n}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Ejecución: por defecto (coherente con Mann–Whitney) resalta MEDIANA\n",
    "if GRAF:\n",
    "    comparacion_visual_violin_box_jitter(df_limpio, rm_outliers=True, seed=RNG_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870f44e",
   "metadata": {},
   "source": [
    "## 8. Conclusiones\n",
    "\n",
    "### **Objetivo**  \n",
    "Entregar una **lectura clara y accionable** del contraste **lluvioso vs sin lluvia**, combinando significancia estadística, **magnitud práctica** (tamaño de efecto) y **robustez** (IC bootstrap), para apoyar decisiones operativas y de comunicación.\n",
    "\n",
    "### **Qué aporta este bloque**  \n",
    "- **Señal estadística**: prueba seleccionada (t/Welch o Mann–Whitney) con p-valor y verificación del IC.  \n",
    "- **Magnitud práctica**: tamaño de efecto (`g` o `r`) con interpretación (trivial/pequeño/mediano/grande).  \n",
    "- **Robustez**: IC bootstrap (réplicas `B` y `seed`) y nota sobre IQR por grupo si se aplicó.  \n",
    "- **Direccionalidad**: diferencia expresada en **minutos** (lluvioso − sin lluvia) y, si se proporciona una referencia, su **impacto porcentual**.  \n",
    "- **Acciones**: recomendaciones según **signo** y **magnitud** del efecto.\n",
    "\n",
    "### **Resultado esperado**  \n",
    "Un bloque Markdown que el lector no técnico puede interpretar rápidamente (¿hay diferencia?, ¿cuánto?, ¿qué implica?) y que también satisface criterios técnicos (IC, tamaño de efecto, supuestos), dejando claro **qué hacer después**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb151c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Conclusiones (Markdown) ---\n",
    "def conclusiones_markdown(\n",
    "    r: dict,\n",
    "    alpha: float = ALFA,\n",
    "    contexto: dict | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Genera conclusiones ejecutivas en Markdown para la comparación 'lluvioso' vs 'sin lluvia'.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    r : dict\n",
    "        Salida de `verificar_supuestos_y_prueba(...)` con claves:\n",
    "        - 'prueba' : str\n",
    "        - 'p_valor' : float\n",
    "        - 'estadistico' : float\n",
    "        - 'use_mean' : bool\n",
    "        - 'dif_minutos' : float         # (lluvioso - sin lluvia) en minutos\n",
    "        - 'ic_minutos' : (float, float) # IC 95% en minutos\n",
    "        - 'n_lluvioso' : int\n",
    "        - 'n_sin_lluvia' : int\n",
    "        - 'tam_efecto' : float\n",
    "        - 'tipo_efecto' : {'g_hedges', 'r_mannwhitney'}\n",
    "    alpha : float\n",
    "        Nivel de significancia para interpretar p-valor y IC.\n",
    "    contexto : dict | None\n",
    "        Información opcional para enriquecer la interpretación, p. ej.:\n",
    "        - 'rm_outliers' : bool\n",
    "        - 'B' : int (réplicas bootstrap)\n",
    "        - 'seed' : int (semilla)\n",
    "        - 'baseline_ref_minutes' : float (p. ej., media de 'sin lluvia' en min)\n",
    "        - 'kpi' : str (nombre del KPI, por defecto 'duración (min)')\n",
    "        - 'ruta' : str (contexto del trayecto, p. ej. \"Loop → O'Hare\")\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    None\n",
    "        Renderiza un bloque Markdown con conclusiones y recomendaciones.\n",
    "    \"\"\"\n",
    "    ctx = contexto or {}\n",
    "    kpi = ctx.get('kpi', 'duración (min)')\n",
    "    ruta = ctx.get('ruta', \"Sábado\")\n",
    "    B = ctx.get('B', NBOOT)\n",
    "    seed = ctx.get('seed', RNG_SEED)\n",
    "    rm_out = ctx.get('rm_outliers', None)\n",
    "    base_ref = ctx.get('baseline_ref_minutes', None)\n",
    "\n",
    "    # --- Lecturas base\n",
    "    p = float(r['p_valor'])\n",
    "    lo, hi = r['ic_minutos']\n",
    "    dif = float(r['dif_minutos'])  # lluvioso - sin lluvia (min)\n",
    "    n_ll, n_sl = int(r['n_lluvioso']), int(r['n_sin_lluvia'])\n",
    "    test = r['prueba']\n",
    "    eff = float(r['tam_efecto'])\n",
    "    eff_kind = r['tipo_efecto']  # 'g_hedges' o 'r_mannwhitney'\n",
    "    sig = p < alpha\n",
    "    cruza_cero = (lo <= 0.0 <= hi)\n",
    "\n",
    "    # --- Etiquetas de tamaño de efecto y dirección ---\n",
    "    if eff_kind == 'g_hedges':\n",
    "        # Guías orientativas para g\n",
    "        if abs(eff) < 0.2: mag = \"trivial\"\n",
    "        elif abs(eff) < 0.5: mag = \"pequeño\"\n",
    "        elif abs(eff) < 0.8: mag = \"moderado\"\n",
    "        else: mag = \"grande\"\n",
    "        eff_txt = f\"g de Hedges = {eff:.3f} ({mag})\"\n",
    "        guias_txt = \"≈0.2 pequeño, 0.5 moderado, 0.8 grande\"\n",
    "    else:\n",
    "        # Guías orientativas para r\n",
    "        if abs(eff) < 0.1: mag = \"trivial\"\n",
    "        elif abs(eff) < 0.3: mag = \"pequeño\"\n",
    "        elif abs(eff) < 0.5: mag = \"mediano\"\n",
    "        else: mag = \"grande\"\n",
    "        eff_txt = f\"r de Mann–Whitney = {eff:.3f} ({mag})\"\n",
    "        guias_txt = \"≈0.1 pequeño, 0.3 mediano, 0.5 grande\"\n",
    "\n",
    "    dir_txt = \"mayor\" if dif > 0 else (\"menor\" if dif < 0 else \"igual\")\n",
    "    sentido_txt = (\n",
    "        f\"En promedio/mediana, **lluvioso** es **{dir_txt}** que **sin lluvia**\"\n",
    "        if dif != 0 else\n",
    "        \"No se observa diferencia puntual entre **lluvioso** y **sin lluvia**\"\n",
    "    )\n",
    "\n",
    "    # --- Impacto porcentual (opcional, requiere referencia) ---\n",
    "    pct_txt = \"\"\n",
    "    if base_ref and base_ref > 0:\n",
    "        pct = (dif / base_ref) * 100.0\n",
    "        pct_txt = f\" (~{pct:+.1f}% vs. referencia sin lluvia ≈ {base_ref:.2f} min)\"\n",
    "\n",
    "    # --- Nota de robustez\n",
    "    robustez_bits = []\n",
    "    robustez_bits.append(f\"IC bootstrap (B={B}, seed={seed})\")\n",
    "    if rm_out is not None:\n",
    "        robustez_bits.append(\"IQR por grupo activo\" if rm_out else \"sin remoción IQR\")\n",
    "    robustez_txt = \" · \".join(robustez_bits)\n",
    "\n",
    "    # --- Decisión e interpretación ---\n",
    "    if sig and not cruza_cero:\n",
    "        decision = f\"**Evidencia estadísticamente significativa** (p={p:.2e} < α={alpha}).\"\n",
    "        ic_read = f\"El IC {int((1-alpha)*100)}% **no** cruza 0 ({lo:.2f}, {hi:.2f}).\"\n",
    "        implicacion = (\n",
    "            \"La diferencia es consistente y **probablemente relevante** si el tamaño de efecto no es trivial.\"\n",
    "            if mag not in (\"trivial\",) else\n",
    "            \"La diferencia es consistente pero su **magnitud práctica parece limitada** (efecto trivial).\"\n",
    "        )\n",
    "    elif sig and cruza_cero:\n",
    "        # caso raro: p<alpha pero IC percentil cruza 0 (discrepancia param/boot)\n",
    "        decision = f\"**Resultado mixto**: p={p:.2e} < α, pero el IC bootstrap cruza 0.\"\n",
    "        ic_read = f\"El IC {int((1-alpha)*100)}% **cruza 0** ({lo:.2f}, {hi:.2f}).\"\n",
    "        implicacion = \"Sugerimos validar con más réplicas bootstrap y/o tamaño muestral mayor.\"\n",
    "    else:\n",
    "        decision = f\"**No se detecta diferencia estadísticamente significativa** (p={p:.2e} ≥ α={alpha}).\"\n",
    "        ic_read = f\"El IC {int((1-alpha)*100)}% incluye 0 ({lo:.2f}, {hi:.2f}).\"\n",
    "        implicacion = \"Con la evidencia actual, la diferencia podría ser nula o demasiado pequeña para detectarse.\"\n",
    "\n",
    "    # --- Recomendaciones accionables (según signo/magnitud) ---\n",
    "    if sig and abs(eff) >= 0.3:\n",
    "        # umbral medio para recomendar acción si hay señal consistente\n",
    "        rec = (\n",
    "            \"- **Operación/planeación**: ajustar buffers o expectativas de servicio en días lluviosos.\\n\"\n",
    "            \"- **Comunicación**: anticipar al usuario/clientes posibles demoras bajo lluvia.\\n\"\n",
    "            \"- **Seguimiento**: monitorear este gap en próximos meses para validar estabilidad.\"\n",
    "        )\n",
    "    elif sig and abs(eff) < 0.3:\n",
    "        rec = (\n",
    "            \"- La diferencia es **pequeña**; considerar acciones **puntuales** (p. ej., microajustes de programación) \"\n",
    "            \"solo si el costo de intervención es bajo.\"\n",
    "        )\n",
    "    else:\n",
    "        rec = (\n",
    "            \"- **No accionar cambios** por ahora. Priorizar **más datos** o analizar subgrupos (hora pico, temporada) \"\n",
    "            \"para descartar efectos locales.\"\n",
    "        )\n",
    "\n",
    "    # --- Ensamble Markdown\n",
    "    md = f\"\"\"\n",
    "### Conclusiones — {ruta}: *lluvioso vs sin lluvia*\n",
    "\n",
    "**Prueba**: {test}  \n",
    "**p-valor**: {p:.2e} · **α** = {alpha}  \n",
    "**Diferencia en {kpi}** (lluvioso − sin lluvia): **{dif:+.2f} min{pct_txt}**  \n",
    "**IC {int((1-alpha)*100)}%**: [{lo:.2f}, {hi:.2f}] min  \n",
    "**Tamaño de efecto**: {eff_txt}  _(guías: {guias_txt})_  \n",
    "**Tamaño muestral**: lluvioso **n={n_ll}**, sin lluvia **n={n_sl}**  \n",
    "**Robustez**: {robustez_txt}\n",
    "\n",
    "> **Lectura**: {sentido_txt}. {decision} {ic_read}\n",
    "\n",
    "**Implicación práctica**  \n",
    "{implicacion}\n",
    "\n",
    "**Siguientes pasos / Recomendaciones**  \n",
    "{rec}\n",
    "\"\"\".strip()\n",
    "\n",
    "    display(Markdown(md))\n",
    "\n",
    "# Renderizar conclusiones en Markdown (usa los flags globales definidos previamente)\n",
    "conclusiones_markdown(resultados_prueba, alpha=ALFA, contexto={\n",
    "    'rm_outliers': RM_OUT,\n",
    "    'B': NBOOT,\n",
    "    'seed': RNG_SEED,\n",
    "    'baseline_ref_minutes': df_limpio.loc[df_limpio['clima'].eq('sin lluvia'), 'duracion_s'].mean() / 60,\n",
    "    'kpi': 'duración (min)',\n",
    "    'ruta': \"Loop -> O'Hare\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394f77e",
   "metadata": {},
   "source": [
    "## OJO:\n",
    "\n",
    "**¿Por qué α = 0.05?**  \n",
    "- Es un estándar ampliamente aceptado que equilibra **riesgo de falso positivo** (Tipo I) y **potencia**.  \n",
    "- **Cuándo cambiarlo**:  \n",
    "  - **α = 0.10** si prima la **sensibilidad** (prefieres detectar diferencias pequeñas aunque aumente el riesgo de falso positivo).  \n",
    "  - **α = 0.01** si las decisiones son **críticas** (p. ej., alto costo por actuar erróneamente) o hay **múltiples comparaciones** (tras Bonferroni/Benjamini–Hochberg).  \n",
    "  - **Pre-especifica** α antes de mirar los datos para evitar sesgos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
